{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordle_solver import WordleSolver\n",
    "from wordle_game import WordleGame\n",
    "\n",
    "import string \n",
    "import sys\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_filename = \"english_words_alpha_dwyl.txt\"\n",
    "target_opener_list_filename = \"english_words_opener.txt\"\n",
    "target_full_list_filename = \"english_words_full.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_wordle_list_filename = \"english_words_original_wordle.txt\"\n",
    "all_original_wordle_words = [word.replace(\"\\r\",\"\").replace(\"\\n\",\"\") for word in open(original_wordle_list_filename, \"r\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_original_wordle_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = open(word_list_filename, \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word.replace(\"\\r\",\"\").replace(\"\\n\",\"\") for word in all_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_on_list_words = list([wordle_word for wordle_word in all_original_wordle_words if wordle_word not in all_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words += not_on_list_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_full_list_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join([word for word in all_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_clusters = 500\n",
    "cluster_groupping_rate = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_length_dict = {}\n",
    "\n",
    "for word in all_words:\n",
    "    word_length = len(word)\n",
    "    if word_length not in words_by_length_dict:\n",
    "        words_by_length_dict[word_length] = []\n",
    "    words_by_length_dict[word_length].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_vectorising_array = [letter for letter in string.ascii_lowercase]\n",
    "random.shuffle(letter_vectorising_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise_word(word):\n",
    "    word_vector = []\n",
    "    for letter in word:\n",
    "        word_vector.append(letter_vectorising_array.index(letter) + 1)\n",
    "    return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_prob_dict(word_list):\n",
    "    if len(word_list) <= 0:\n",
    "        return []\n",
    "    letter_freq_dict = {}\n",
    "    for letter in string.ascii_lowercase:\n",
    "        letter_freq_dict[letter] = 0\n",
    "    for word in word_list:\n",
    "        for letter in word:\n",
    "            letter_freq_dict[letter] += 1\n",
    "    letter_prob_dict = {}\n",
    "    total_letters = sum([len(word) for word in word_list])\n",
    "    for letter in letter_freq_dict.keys():\n",
    "        letter_prob_dict[letter] = (letter_freq_dict[letter] / total_letters)\n",
    "\n",
    "    return letter_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_positional_prob_dict(words):\n",
    "    positional_prob = []\n",
    "    for i in range(0, len(words[0])):\n",
    "        letter_list = [word[i] for word in words]\n",
    "        positional_prob.append(get_letter_prob_dict(letter_list))\n",
    "    return positional_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_words_with_letter_positional_prob(words):\n",
    "    letter_position_prob = get_letter_positional_prob_dict(words)\n",
    "    words_with_prob = []\n",
    "    for word in words:\n",
    "        score = 1\n",
    "        for i in range(0, len(letter_position_prob)):\n",
    "            if letter_position_prob[i]:\n",
    "                score *= letter_position_prob[i][word[i]]\n",
    "        words_with_prob.append((word, score))\n",
    "    words_with_prob.sort(key=lambda element: element[1], reverse=True)\n",
    "    return [word for (word, _) in words_with_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_entropy_dict(words):\n",
    "    word_entropy_dict = {}\n",
    "    game = WordleGame(None, word_length)\n",
    "    game.word_length = len(words[0])\n",
    "    game.word_list = words\n",
    "    solver = WordleSolver(None, word_length)\n",
    "    solver.word_length = len(words[0])\n",
    "    solver.word_list = words\n",
    "    word_count = len(words)\n",
    "    hidden_word_list = words.copy()\n",
    "    random.shuffle(hidden_word_list)\n",
    "    for word in words:\n",
    "        possible_word_count = []\n",
    "        for hidden_word in hidden_word_list:\n",
    "            solver.reset()\n",
    "            game.hidden_word = hidden_word\n",
    "            response_symbols = game.guess(word)\n",
    "            solver.input_guess_result(word, response_symbols)\n",
    "            solver.update_pattern_paramters()\n",
    "            possible_word_count.append(len(solver.get_possible_words()))\n",
    "        probs = [(sys.float_info.min + (count / word_count)) for count in possible_word_count]\n",
    "        entropy = 0 - sum([prob * math.log(prob, 2) for prob in probs])\n",
    "        word_entropy_dict[word] = entropy\n",
    "    return word_entropy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_words_with_entropy(words):\n",
    "    word_entropies_dict = get_word_entropy_dict(words)\n",
    "    words_with_entopies = [(word, word_entropies_dict[word]) for word in words]\n",
    "    words_with_entopies.sort(key=lambda element: element[1], reverse=False)\n",
    "    sorted_words = [words_with_entropy[0] for words_with_entropy in words_with_entopies]\n",
    "    return sorted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opener_list(word_list):\n",
    "    if len(word_list) < min_clusters:\n",
    "        return word_list\n",
    "    word_list_vectors = [vectorise_word(word) for word in word_list]\n",
    "    X = np.array(word_list_vectors)\n",
    "    cluster_n = int(len(word_list) * cluster_groupping_rate)\n",
    "    if cluster_n < min_clusters:\n",
    "        cluster_n = min_clusters\n",
    "    print(f\"clusters: {cluster_n}\")\n",
    "    km = KMeans(\n",
    "            n_clusters=cluster_n, init='random',\n",
    "            n_init=10, max_iter=600, \n",
    "            tol=1e-04, random_state=0,\n",
    "            algorithm='full'\n",
    "        )\n",
    "    y_km = km.fit_predict(X)\n",
    "    clusters = []\n",
    "    for i in range(0, cluster_n):\n",
    "        clusters.append([])\n",
    "    for i in range(0, len(y_km)):\n",
    "        word = word_list[i]\n",
    "        cluster_index = y_km[i]\n",
    "        clusters[cluster_index].append(word)\n",
    "    new_word_list = []\n",
    "    for cluster_words in clusters:\n",
    "        best_words = sort_words_with_entropy(cluster_words)\n",
    "        # best_words = sort_words_with_letter_positional_prob(cluster_words)\n",
    "        if len(best_words[0]) == 5 and len(all_original_wordle_words) > 0:\n",
    "            for best_word in best_words:\n",
    "                if best_word in all_original_wordle_words:\n",
    "                    new_word_list.append(best_word)\n",
    "                    break\n",
    "        else:\n",
    "            new_word_list.append(best_words[0])\n",
    "    return new_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length in words_by_length_dict.keys():\n",
    "    print(f\"word length: {length}\\tnumber of words: {len(words_by_length_dict[length])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_lists_by_length = {}\n",
    "\n",
    "for length in words_by_length_dict.keys():\n",
    "    print(f\"processing word length {length}\")\n",
    "    opener_lists_by_length[length] = get_opener_list(words_by_length_dict[length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_opener_list = []\n",
    "\n",
    "for length in opener_lists_by_length.keys():\n",
    "    full_opener_list += opener_lists_by_length[length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_opener_list_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join([word for word in full_opener_list]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c29844a0a6289b07ec9bd49bfbf82b25be0a16fcb62431206df354e3cda954d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
